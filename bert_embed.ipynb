{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import os\n",
    "from ast import literal_eval\n",
    "\n",
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/content/drive/Shareddrives/AmorePacific2021/5.newcode/dataset/'\n",
    "DATA_NAME = 'amore_data_above8_rating.csv'      ## Already preprocessed (Clean reviews)\n",
    "df = pd.read_csv(DATASET_PATH + DATA_NAME, converters={'review_split': literal_eval})\n",
    "\n",
    "## Reviews splitted by sentences\n",
    "reviews = df.review_split.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT embedding module\n",
    "'''\n",
    "Reference : https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#32-understanding-the-output\n",
    "'''\n",
    "class Embed_custom:\n",
    "    def __init__(self, pretrain_ver='Kyoungmin/beauty-base-KLCP2'):     ## Domain Adaptation한 후 huggingface에 올린 pretrained-model 사용\n",
    "        self.ver = pretrain_ver\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.ver)\n",
    "        self.model = BertForMaskedLM.from_pretrained(self.ver, output_hidden_states = True)\n",
    "\n",
    "    ## Tokenization\n",
    "    def tokenization_custom(self, sent):\n",
    "        marked_text = '[CLS]' + sent + '[SEP]'\n",
    "        tokenized_text = self.tokenizer.tokenize(marked_text)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "        ## 데이터(리뷰텍스트) 상 300자 넘는 리뷰(문장)이 거의 없어서 아래처럼 cutpoint 설정함\n",
    "        if len(indexed_tokens) > 300 :\n",
    "          cut_end = (len(indexed_tokens)-300)//2\n",
    "          cut_start = len(indexed_tokens) - 300 - cut_end\n",
    "          indexed_tokens = indexed_tokens[cut_start:(len(indexed_tokens)-cut_end)]\n",
    "\n",
    "        return indexed_tokens\n",
    "\n",
    "    ## Embedding\n",
    "    def _transformer_custom(self, sent):\n",
    "        indexed_tokens = self.tokenization_custom(sent)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor)\n",
    "\n",
    "        hidden_states = outputs[1]\n",
    "        token_vecs = hidden_states[-2][0]    ## Followed tutorial (Reference)\n",
    "        sent_embed = torch.mean(token_vecs, dim=0)\n",
    "        return sent_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Embedding\n",
    "module = Embed_custom()\n",
    "\n",
    "t0 = time.time()\n",
    "rev_embed = []\n",
    "for rev in tqdm(reviews):\n",
    "  sent_embed = []\n",
    "  for sent in rev:\n",
    "    sent_embed.append(module._transformer_custom(sent))\n",
    "  rev_embed.append(sent_embed)\n",
    "\n",
    "print('Elapsed time (sec.) :', time.time()-t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
